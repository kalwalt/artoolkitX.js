<html>
<body>
	<script type='text/javascript'>
	window.artoolkitX_wasm_url = '../SDK/lib/artoolkitx.wasm';
	</script>
<script src="js/three.min.js"></script>
<script type="module" src="../SDK/lib/artoolkitX.api.js"></script>



<video id="v" src="Data/output_4.mp4" width="320" height="240" loop="" controls="" autoplay webkit-playsinline></video>

<script id="vert" type="glsl-vertex">
precision highp float;
precision lowp int;

uniform mat4 cameraMatrix;
uniform mat4 transformationMatrix;

varying vec2 vUv;

void main(void)
{
	vUv = uv;
	gl_Position = cameraMatrix * transformationMatrix * vec4(position, 1.0);
}
</script>

<script id="frag" type="glsl-fragment">
precision highp float;
precision lowp int;

varying vec2 vUv;

void main(void)
{
	gl_FragColor = vec4(vUv, 1.0, 1.0);
}
</script>

<script type="module">
import ARController from '../SDK/lib/artoolkitX.api.js';

const cameraParam = './Data/camera_para.dat';

const config = {
    cameraParam: cameraParam,
    width: 320,
    height: 240
};

var trackable = {
    trackableType: "single_barcode",
    barcodeId: 1
}

var ar1, interval;
const USE_SHADER = true;

window.addEventListener('artoolkitX-loaded', () => {
var camera_mat = new Float32Array(16);
var cMat = new THREE.Matrix4();
var tMat = new THREE.Matrix4();

var shaderMaterial = new THREE.ShaderMaterial({
	uniforms: {
		cameraMatrix: {type: 'm4', value: cMat },
		transformationMatrix: {type: 'm4', value: tMat }
	},
	vertexShader: vert.text,
	fragmentShader: frag.text
});
var renderer = new THREE.WebGLRenderer();
var scene = new THREE.Scene();
// Create a camera and a marker root object for your Three.js scene.
const camera = new THREE.PerspectiveCamera( 50, 320 /240, 0.0001, 100000 );
camera.matrixAutoUpdate = false;
const cameraRoot = new THREE.Object3D();
cameraRoot.add(camera);
scene.add(camera);

var light = new THREE.PointLight(0xffffff);
light.position.set(400, 500, 100);
scene.add(light);
var light = new THREE.PointLight(0xffffff);
light.position.set(-400, -500, -100);
scene.add(light);

var markerRoot = new THREE.Object3D();

markerRoot.wasVisible = false;
markerRoot.markerMatrix = new Float64Array(16);
markerRoot.matrixAutoUpdate = false;
camera.matrixAutoUpdate = false;

// Add the marker root to your scene.
scene.add(markerRoot);
var video = document.getElementById('v');
var arController = new ARController(v, cameraParam);

	arController.addEventListener('getMarker', (trackableInfo) => {
			console.log("TrackableID: " + trackableInfo.data.trackableId);
			const transformation = trackableInfo.data.transformation;
			const markerVisible = trackableInfo.visible;
			markerRoot.visible = markerVisible;
			if (USE_SHADER) {
				shaderMaterial.uniforms.transformationMatrix.value.fromArray(transformation);
			  //arController.arglCameraViewRHf(transformation, shaderMaterial.uniforms.transformationMatrix.value.elements);
			} else {
				markerRoot.matrix.fromArray(transformation)
			}
	});
var video = document.getElementById('v');
	try {
			arController.start().then( () => {
					console.log("start done");
					renderer.setSize(v.width, v.height);

					document.body.appendChild(renderer.domElement);
					const camMatrix = arController.getCameraMatrix(0.0001, 100000);
					const fovy = 2 * Math.atan(1 / camMatrix[5]) * 180 / Math.PI;
					const vh = arController.videoHeight
					const vw = arController.videoWidth
					const cw = arController.canvas.width
					const ch = arController.canvas.height

					// if (vw < vh) {
					//     camera.fov = Math.abs(fovy) * (vh / vw);
					// } else {
					//     if (cw / ch > vw / vh) {
					//         // Video Y FOV is limited so we must limit 3D camera FOV to match
					//         camera.fov = Math.abs(fovy) * (vw / vh) / (cw / ch);
					//     } else {
					//         // Video Y FOV is limited so we must limit 3D camera FOV to match
					//         camera.fov = Math.abs(fovy);
					//     }
					// }
					if (USE_SHADER) {
						shaderMaterial.uniforms.cameraMatrix.value.fromArray(camMatrix);
					} else {
						camera.projectionMatrix.fromArray(camMatrix);
						camera.updateProjectionMatrix();
					}
					var videoTex = new THREE.Texture(arController.image);
					videoTex.minFilter = THREE.LinearFilter;
					videoTex.flipY = false;

					// Then create a plane textured with the video.
					var plane = new THREE.Mesh(
					new THREE.PlaneBufferGeometry(2, 2),
					new THREE.MeshBasicMaterial({map: videoTex, side: THREE.DoubleSide})
					);

					// The video plane shouldn't care about the z-buffer.
					plane.material.depthTest = false;
					plane.material.depthWrite = false;

					// Create a camera and a scene for the video plane and
					// add the camera and the video plane to the scene.
					var videoCamera = new THREE.OrthographicCamera(-1, 1, -1, 1, -1, 1);
					var videoScene = new THREE.Scene();
					videoScene.add(plane);
					videoScene.add(videoCamera);

					markerRoot.wasVisible = false;
					markerRoot.markerMatrix = new Float64Array(16);
					markerRoot.matrixAutoUpdate = false;

					// Add the marker models and suchlike into your marker root object.
					var cube = new THREE.Mesh(
						new THREE.BoxGeometry(100,100,100),
						USE_SHADER ?
							shaderMaterial :
							new THREE.MeshLambertMaterial({ color: 0xffffff, wireframe: false })
					);
					cube.position.z = 5;
					markerRoot.add(cube);
					markerRoot.visible = true;

					var trackableId = arController.addTrackable(trackable);

					interval = setInterval(function() {

							arController.process(video);
							videoTex.needsUpdate = true;
							const ac = renderer.autoClear;
							renderer.autoClear = false;
							renderer.clear();
							renderer.render(videoScene, videoCamera);
							renderer.render(scene, camera);
							renderer.autoClear = ac;

					}, 13);
					ar1 = arController;
					
			});
	}
	catch (e) {
			console.log(e);
	}
});

window.closeVideo = function() {
    if(ar1) {
        ar1.dispose();
        clearInterval(interval);
    }
    else {
        console.error("Trying to close before opened");
    }
}
</script>
<div id='matrix'></div>
</body>
</html>
